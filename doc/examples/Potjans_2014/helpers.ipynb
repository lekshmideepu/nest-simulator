{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nPynest microcircuit helpers\n---------------------------\n\nHelper functions for the simulation and evaluation of the microcircuit.\n\nAuthors\n~~~~~~~~\n\nHendrik Rothe, Hannah Bos, Sacha van Albada; May 2016\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport os\nimport sys\nif 'DISPLAY' not in os.environ:\n    import matplotlib\n    matplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\n\n\ndef compute_DC(net_dict, w_ext):\n    \"\"\" Computes DC input if no Poisson input is provided to the microcircuit.\n\n    Parameters\n    ----------\n    net_dict\n        Parameters of the microcircuit.\n    w_ext\n        Weight of external connections.\n\n    Returns\n    -------\n    DC\n        DC input, which compensates lacking Poisson input.\n    \"\"\"\n    DC = (\n        net_dict['bg_rate'] * net_dict['K_ext'] *\n        w_ext * net_dict['neuron_params']['tau_syn_E'] * 0.001\n        )\n    return DC\n\n\ndef get_weight(PSP_val, net_dict):\n    \"\"\" Computes weight to elicit a change in the membrane potential.\n\n    This function computes the weight which elicits a change in the membrane\n    potential of size PSP_val. To implement this, the weight is calculated to\n    elicit a current that is high enough to implement the desired change in the\n    membrane potential.\n\n    Parameters\n    ----------\n    PSP_val\n        Evoked postsynaptic potential.\n    net_dict\n        Dictionary containing parameters of the microcircuit.\n\n    Returns\n    -------\n    PSC_e\n        Weight value(s).\n\n    \"\"\"\n    C_m = net_dict['neuron_params']['C_m']\n    tau_m = net_dict['neuron_params']['tau_m']\n    tau_syn_ex = net_dict['neuron_params']['tau_syn_ex']\n\n    PSC_e_over_PSP_e = (((C_m) ** (-1) * tau_m * tau_syn_ex / (\n        tau_syn_ex - tau_m) * ((tau_m / tau_syn_ex) ** (\n            - tau_m / (tau_m - tau_syn_ex)) - (tau_m / tau_syn_ex) ** (\n                - tau_syn_ex / (tau_m - tau_syn_ex)))) ** (-1))\n    PSC_e = (PSC_e_over_PSP_e * PSP_val)\n    return PSC_e\n\n\ndef get_total_number_of_synapses(net_dict):\n    \"\"\" Returns the total number of synapses between all populations.\n\n    The first index (rows) of the output matrix is the target population\n    and the second (columns) the source population. If a scaling of the\n    synapses is intended this is done in the main simulation script and the\n    variable 'K_scaling' is ignored in this function.\n\n    Parameters\n    ----------\n    net_dict\n        Dictionary containing parameters of the microcircuit.\n    N_full\n        Number of neurons in all populations.\n    number_N\n        Total number of populations.\n    conn_probs\n        Connection probabilities of the eight populations.\n    scaling\n        Factor that scales the number of neurons.\n\n    Returns\n    -------\n    K\n        Total number of synapses with\n        dimensions [len(populations), len(populations)].\n\n    \"\"\"\n    N_full = net_dict['N_full']\n    number_N = len(N_full)\n    conn_probs = net_dict['conn_probs']\n    scaling = net_dict['N_scaling']\n    prod = np.outer(N_full, N_full)\n    n_syn_temp = np.log(1. - conn_probs)/np.log((prod - 1.) / prod)\n    N_full_matrix = np.column_stack(\n        (N_full for i in list(range(number_N)))\n        )\n    # If the network is scaled the indegrees are calculated in the same\n    # fashion as in the original version of the circuit, which is\n    # written in sli.\n    K = (((n_syn_temp * (\n        N_full_matrix * scaling).astype(int)) / N_full_matrix).astype(int))\n    return K\n\n\ndef synapses_th_matrix(net_dict, stim_dict):\n    \"\"\" Computes number of synapses between thalamus and microcircuit.\n\n    This function ignores the variable, which scales the number of synapses.\n    If this is intended the scaling is performed in the main simulation script.\n\n    Parameters\n    ----------\n    net_dict\n        Dictionary containing parameters of the microcircuit.\n    stim_dict\n        Dictionary containing parameters of stimulation settings.\n    N_full\n        Number of neurons in the eight populations.\n    number_N\n        Total number of populations.\n    conn_probs\n        Connection probabilities of the thalamus to the eight populations.\n    scaling\n        Factor that scales the number of neurons.\n    T_full\n        Number of thalamic neurons.\n\n    Returns\n    -------\n    K\n        Total number of synapses.\n\n    \"\"\"\n    N_full = net_dict['N_full']\n    number_N = len(N_full)\n    scaling = net_dict['N_scaling']\n    conn_probs = stim_dict['conn_probs_th']\n    T_full = stim_dict['n_thal']\n    prod = (T_full * N_full).astype(float)\n    n_syn_temp = np.log(1. - conn_probs)/np.log((prod - 1.)/prod)\n    K = (((n_syn_temp * (N_full * scaling).astype(int))/N_full).astype(int))\n    return K\n\n\ndef adj_w_ext_to_K(K_full, K_scaling, w, w_from_PSP, DC, net_dict, stim_dict):\n    \"\"\" Adjustment of weights to scaling is performed.\n\n    The recurrent and external weights are adjusted to the scaling\n    of the indegrees. Extra DC input is added to compensate the scaling\n    and preserve the mean and variance of the input.\n\n    Parameters\n    ----------\n    K_full\n        Total number of connections between the eight populations.\n    K_scaling\n        Scaling factor for the connections.\n    w\n        Weight matrix of the connections of the eight populations.\n    w_from_PSP\n        Weight of the external connections.\n    DC\n        DC input to the eight populations.\n    net_dict\n        Dictionary containing parameters of the microcircuit.\n    stim_dict\n        Dictionary containing stimulation parameters.\n    tau_syn_E\n        Time constant of the external postsynaptic excitatory current.\n    full_mean_rates\n        Mean rates of the eight populations in the full scale version.\n    K_ext\n        Number of external connections to the eight populations.\n    bg_rate\n        Rate of the Poissonian spike generator.\n\n    Returns\n    -------\n    w_new\n        Adjusted weight matrix.\n    w_ext_new\n        Adjusted external weight.\n    I_ext\n        Extra DC input.\n\n    \"\"\"\n    tau_syn_E = net_dict['neuron_params']['tau_syn_E']\n    full_mean_rates = net_dict['full_mean_rates']\n    w_mean = w_from_PSP\n    K_ext = net_dict['K_ext']\n    bg_rate = net_dict['bg_rate']\n    w_new = w / np.sqrt(K_scaling)\n    I_ext = np.zeros(len(net_dict['populations']))\n    x1_all = w * K_full * full_mean_rates\n    x1_sum = np.sum(x1_all, axis=1)\n    if net_dict['poisson_input']:\n        x1_ext = w_mean * K_ext * bg_rate\n        w_ext_new = w_mean / np.sqrt(K_scaling)\n        I_ext = 0.001 * tau_syn_E * (\n            (1. - np.sqrt(K_scaling)) * x1_sum + (\n                1. - np.sqrt(K_scaling)) * x1_ext) + DC\n    else:\n        w_ext_new = w_from_PSP / np.sqrt(K_scaling)\n        I_ext = 0.001 * tau_syn_E * (\n            (1. - np.sqrt(K_scaling)) * x1_sum) + DC\n    return w_new, w_ext_new, I_ext\n\n\ndef read_name(path, name):\n    \"\"\" Reads names and ids of spike detector.\n\n    The names of the spike detectors are gathered and the lowest and\n    highest id of each spike detector is computed. If the simulation was\n    run on several threads or mpi-processes, one name per spike detector\n    per mpi-process/thread is extracted.\n\n    Parameters\n    ------------\n    path\n        Path where the spike detector files are stored.\n    name\n        Name of the spike detector.\n\n    Returns\n    -------\n    files\n        Name of all spike detectors, which are located in the path.\n    gids\n        Lowest and highest ids of the spike detectors.\n\n    \"\"\"\n    # Import filenames$\n    files = []\n    for file in os.listdir(path):\n        if file.endswith('.gdf') and file.startswith(name):\n            temp = file.split('-')[0] + '-' + file.split('-')[1]\n            if temp not in files:\n                files.append(temp)\n\n    # Import GIDs\n    gidfile = open(path + 'population_GIDs.dat', 'r')\n    gids = []\n    for l in gidfile:\n        a = l.split()\n        gids.append([int(a[0]), int(a[1])])\n    files = sorted(files)\n    return files, gids\n\n\ndef load_spike_times(path, name, begin, end):\n    \"\"\" Loads spike times of each spike detector.\n\n    Parameters\n    -----------\n    path\n        Path where the files with the spike times are stored.\n    name\n        Name of the spike detector.\n    begin\n        Lower boundary value to load spike times.\n    end\n        Upper boundary value to load spike times.\n\n    Returns\n    -------\n    data\n        Dictionary containing spike times in the interval from 'begin'\n        to 'end'.\n\n    \"\"\"\n    files, gids = read_name(path, name)\n    data = {}\n    for i in list(range(len(files))):\n        all_names = os.listdir(path)\n        temp3 = [\n            all_names[x] for x in list(range(len(all_names)))\n            if all_names[x].endswith('gdf') and\n            all_names[x].startswith('spike') and\n            (all_names[x].split('-')[0] + '-' + all_names[x].split('-')[1]) in\n            files[i]\n            ]\n        data_temp = [np.loadtxt(os.path.join(path, f)) for f in temp3]\n        data_concatenated = np.concatenate(data_temp)\n        data_raw = data_concatenated[np.argsort(data_concatenated[:, 1])]\n        idx = ((data_raw[:, 1] > begin) * (data_raw[:, 1] < end))\n        data[i] = data_raw[idx]\n    return data\n\n\ndef plot_raster(path, name, begin, end):\n    \"\"\" Creates a spike raster plot of the microcircuit.\n\n    Parameters\n    -----------\n    path\n        Path where the spike times are stored.\n    name\n        Name of the spike detector.\n    begin\n        Initial value of spike times to plot.\n    end\n        Final value of spike times to plot.\n\n    Returns\n    -------\n    None\n\n    \"\"\"\n    files, gids = read_name(path, name)\n    data_all = load_spike_times(path, name, begin, end)\n    highest_gid = gids[-1][-1]\n    gids_numpy = np.asarray(gids)\n    gids_numpy_changed = abs(gids_numpy - highest_gid) + 1\n    L23_label_pos = (gids_numpy_changed[0][0] + gids_numpy_changed[1][1])/2\n    L4_label_pos = (gids_numpy_changed[2][0] + gids_numpy_changed[3][1])/2\n    L5_label_pos = (gids_numpy_changed[4][0] + gids_numpy_changed[5][1])/2\n    L6_label_pos = (gids_numpy_changed[6][0] + gids_numpy_changed[7][1])/2\n    ylabels = ['L23', 'L4', 'L5', 'L6']\n    color_list = [\n        '#000000', '#888888', '#000000', '#888888',\n        '#000000', '#888888', '#000000', '#888888'\n        ]\n    Fig1 = plt.figure(1, figsize=(8, 6))\n    for i in list(range(len(files))):\n        times = data_all[i][:, 1]\n        neurons = np.abs(data_all[i][:, 0] - highest_gid) + 1\n        plt.plot(times, neurons, '.', color=color_list[i])\n    plt.xlabel('time [ms]', fontsize=18)\n    plt.xticks(fontsize=18)\n    plt.yticks(\n        [L23_label_pos, L4_label_pos, L5_label_pos, L6_label_pos],\n        ylabels, rotation=10, fontsize=18\n        )\n    plt.savefig(os.path.join(path, 'raster_plot.png'), dpi=300)\n    plt.show()\n\n\ndef fire_rate(path, name, begin, end):\n    \"\"\" Computes firing rate and standard deviation of it.\n\n    The firing rate of each neuron for each population is computed and stored\n    in a numpy file in the directory of the spike detectors. The mean firing\n    rate and its standard deviation is displayed for each population.\n\n    Parameters\n    -----------\n    path\n        Path where the spike times are stored.\n    name\n        Name of the spike detector.\n    begin\n        Initial value of spike times to calculate the firing rate.\n    end\n        Final value of spike times to calculate the firing rate.\n\n    Returns\n    -------\n    None\n\n    \"\"\"\n    files, gids = read_name(path, name)\n    data_all = load_spike_times(path, name, begin, end)\n    rates_averaged_all = []\n    rates_std_all = []\n    for h in list(range(len(files))):\n        n_fil = data_all[h][:, 0]\n        n_fil = n_fil.astype(int)\n        count_of_n = np.bincount(n_fil)\n        count_of_n_fil = count_of_n[gids[h][0]-1:gids[h][1]]\n        rate_each_n = count_of_n_fil * 1000. / (end - begin)\n        rate_averaged = np.mean(rate_each_n)\n        rate_std = np.std(rate_each_n)\n        rates_averaged_all.append(float('%.3f' % rate_averaged))\n        rates_std_all.append(float('%.3f' % rate_std))\n        np.save(os.path.join(path, ('rate' + str(h) + '.npy')), rate_each_n)\n    print('Mean rates: %r Hz' % rates_averaged_all)\n    print('Standard deviation of rates: %r Hz' % rates_std_all)\n\n\ndef boxplot(net_dict, path):\n    \"\"\" Creates a boxblot of the firing rates of the eight populations.\n\n    To create the boxplot, the firing rates of each population need to be\n    computed with the function 'fire_rate'.\n\n    Parameters\n    -----------\n    net_dict\n        Dictionary containing parameters of the microcircuit.\n    path\n        Path were the firing rates are stored.\n\n    Returns\n    -------\n    None\n\n    \"\"\"\n    pops = net_dict['N_full']\n    reversed_order_list = list(range(len(pops) - 1, -1, -1))\n    list_rates_rev = []\n    for h in reversed_order_list:\n        list_rates_rev.append(\n            np.load(os.path.join(path, ('rate' + str(h) + '.npy')))\n            )\n    pop_names = net_dict['populations']\n    label_pos = list(range(len(pops), 0, -1))\n    color_list = ['#888888', '#000000']\n    medianprops = dict(linestyle='-', linewidth=2.5, color='firebrick')\n    fig, ax1 = plt.subplots(figsize=(10, 6))\n    bp = plt.boxplot(list_rates_rev, 0, 'rs', 0, medianprops=medianprops)\n    plt.setp(bp['boxes'], color='black')\n    plt.setp(bp['whiskers'], color='black')\n    plt.setp(bp['fliers'], color='red', marker='+')\n    for h in list(range(len(pops))):\n        boxX = []\n        boxY = []\n        box = bp['boxes'][h]\n        for j in list(range(5)):\n            boxX.append(box.get_xdata()[j])\n            boxY.append(box.get_ydata()[j])\n        boxCoords = list(zip(boxX, boxY))\n        k = h % 2\n        boxPolygon = Polygon(boxCoords, facecolor=color_list[k])\n        ax1.add_patch(boxPolygon)\n    plt.xlabel('firing rate [Hz]', fontsize=18)\n    plt.yticks(label_pos, pop_names, fontsize=18)\n    plt.xticks(fontsize=18)\n    plt.savefig(os.path.join(path, 'box_plot.png'), dpi=300)\n    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}